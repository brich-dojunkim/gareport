import json
from datetime import datetime
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import (
    DateRange, Dimension, Metric, RunReportRequest, OrderBy
)
import pandas as pd
from google.oauth2 import service_account

class WebsiteKnowledgeGenerator:
    def __init__(self, credentials_path, property_id):
        """ì›¹ì‚¬ì´íŠ¸ ì§€ì‹ JSON ìƒì„±ê¸°"""
        self.property_id = property_id
        
        # GA4 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        credentials = service_account.Credentials.from_service_account_file(
            credentials_path,
            scopes=['https://www.googleapis.com/auth/analytics.readonly']
        )
        self.client = BetaAnalyticsDataClient(credentials=credentials)
    
    def generate_knowledge_json(self, filename="website_knowledge.json"):
        """ì›¹ì‚¬ì´íŠ¸ ì§€ì‹ì„ JSON íŒŒì¼ë¡œ ìƒì„±"""
        print("ğŸ” ì›¹ì‚¬ì´íŠ¸ ì§€ì‹ ìˆ˜ì§‘ ì‹œì‘...")
        
        knowledge = {
            "generated_at": datetime.now().isoformat(),
            "property_id": self.property_id,
            "website_structure": {},
            "pages": {},
            "traffic_sources": {},
            "events": {},
            "user_journey": {},
            "business_insights": {}
        }
        
        # 1. í˜ì´ì§€ êµ¬ì¡° ìˆ˜ì§‘
        print("  ğŸ“„ í˜ì´ì§€ êµ¬ì¡° ìˆ˜ì§‘ ì¤‘...")
        pages_data = self._get_all_pages()
        knowledge["pages"] = self._analyze_pages(pages_data)
        knowledge["website_structure"] = self._analyze_website_structure(pages_data)
        
        # 2. íŠ¸ë˜í”½ ì†ŒìŠ¤ ìˆ˜ì§‘
        print("  ğŸš€ íŠ¸ë˜í”½ ì†ŒìŠ¤ ìˆ˜ì§‘ ì¤‘...")
        traffic_data = self._get_traffic_sources()
        knowledge["traffic_sources"] = self._analyze_traffic_sources(traffic_data)
        
        # 3. ì´ë²¤íŠ¸ ìˆ˜ì§‘
        print("  ğŸ¯ ì´ë²¤íŠ¸ ìˆ˜ì§‘ ì¤‘...")
        events_data = self._get_events()
        knowledge["events"] = self._analyze_events(events_data)
        
        # 4. ì‚¬ìš©ì ì—¬ì • ìˆ˜ì§‘
        print("  ğŸ‘¥ ì‚¬ìš©ì ì—¬ì • ìˆ˜ì§‘ ì¤‘...")
        landing_data = self._get_landing_pages()
        knowledge["user_journey"] = self._analyze_user_journey(landing_data)
        
        # 5. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        print("  ğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘...")
        knowledge["business_insights"] = self._generate_business_insights(
            pages_data, traffic_data, events_data, landing_data
        )
        
        # JSON íŒŒì¼ ì €ì¥
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(knowledge, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ì§€ì‹ JSON ìƒì„± ì™„ë£Œ: {filename}")
        self._print_summary(knowledge)
        
        return knowledge
    
    def _get_all_pages(self, days=90):
        """ëª¨ë“  í˜ì´ì§€ ë°ì´í„° ìˆ˜ì§‘"""
        request = RunReportRequest(
            property=f"properties/{self.property_id}",
            dimensions=[
                Dimension(name="pagePath"),
                Dimension(name="pageTitle"),
            ],
            metrics=[
                Metric(name="screenPageViews"),
                Metric(name="activeUsers"),
                Metric(name="sessions"),
                Metric(name="engagementRate"),
                Metric(name="averageSessionDuration"),
            ],
            date_ranges=[DateRange(start_date=f"{days}daysAgo", end_date="today")],
            order_bys=[OrderBy(metric=OrderBy.MetricOrderBy(metric_name="screenPageViews"), desc=True)],
            limit=1000
        )
        response = self.client.run_report(request=request)
        return self._response_to_dict_list(response)
    
    def _get_traffic_sources(self, days=30):
        """íŠ¸ë˜í”½ ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
        request = RunReportRequest(
            property=f"properties/{self.property_id}",
            dimensions=[
                Dimension(name="sessionSource"),
                Dimension(name="sessionMedium"),
                Dimension(name="pagePath"),
            ],
            metrics=[
                Metric(name="sessions"),
                Metric(name="activeUsers"),
                Metric(name="engagementRate"),
            ],
            date_ranges=[DateRange(start_date=f"{days}daysAgo", end_date="today")],
            order_bys=[OrderBy(metric=OrderBy.MetricOrderBy(metric_name="sessions"), desc=True)],
            limit=500
        )
        response = self.client.run_report(request=request)
        return self._response_to_dict_list(response)
    
    def _get_events(self, days=30):
        """ì´ë²¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘"""
        request = RunReportRequest(
            property=f"properties/{self.property_id}",
            dimensions=[
                Dimension(name="eventName"),
                Dimension(name="pagePath"),
            ],
            metrics=[
                Metric(name="eventCount"),
                Metric(name="activeUsers"),
            ],
            date_ranges=[DateRange(start_date=f"{days}daysAgo", end_date="today")],
            order_bys=[OrderBy(metric=OrderBy.MetricOrderBy(metric_name="eventCount"), desc=True)],
            limit=200
        )
        response = self.client.run_report(request=request)
        return self._response_to_dict_list(response)
    
    def _get_landing_pages(self, days=30):
        """ì§„ì… í˜ì´ì§€ ë°ì´í„° ìˆ˜ì§‘"""
        request = RunReportRequest(
            property=f"properties/{self.property_id}",
            dimensions=[
                Dimension(name="landingPage"),
            ],
            metrics=[
                Metric(name="sessions"),
                Metric(name="bounceRate"),
                Metric(name="engagementRate"),
            ],
            date_ranges=[DateRange(start_date=f"{days}daysAgo", end_date="today")],
            order_bys=[OrderBy(metric=OrderBy.MetricOrderBy(metric_name="sessions"), desc=True)],
            limit=100
        )
        response = self.client.run_report(request=request)
        return self._response_to_dict_list(response)
    
    def _response_to_dict_list(self, response):
        """GA4 ì‘ë‹µì„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        dimension_headers = [header.name for header in response.dimension_headers]
        metric_headers = [header.name for header in response.metric_headers]
        
        data = []
        for row in response.rows:
            row_data = {}
            
            # ì°¨ì› ë°ì´í„°
            for i, dimension_value in enumerate(row.dimension_values):
                row_data[dimension_headers[i]] = dimension_value.value
            
            # ì¸¡ì •í•­ëª© ë°ì´í„°
            for i, metric_value in enumerate(row.metric_values):
                value = metric_value.value
                try:
                    value = float(value)
                except ValueError:
                    pass
                row_data[metric_headers[i]] = value
            
            data.append(row_data)
        
        return data
    
    def _analyze_pages(self, pages_data):
        """í˜ì´ì§€ ë¶„ì„"""
        return {
            "total_pages": len(pages_data),
            "top_pages": pages_data[:20],  # ìƒìœ„ 20ê°œ í˜ì´ì§€
            "page_categories": self._categorize_pages(pages_data),
            "performance_summary": {
                "total_pageviews": sum(p.get('screenPageViews', 0) for p in pages_data),
                "total_users": sum(p.get('activeUsers', 0) for p in pages_data),
                "avg_engagement": sum(p.get('engagementRate', 0) for p in pages_data) / len(pages_data) if pages_data else 0
            }
        }
    
    def _categorize_pages(self, pages_data):
        """í˜ì´ì§€ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        categories = {}
        
        for page in pages_data:
            path = page.get('pagePath', '')
            category = self._get_page_category(path)
            
            if category not in categories:
                categories[category] = {
                    "count": 0,
                    "total_views": 0,
                    "examples": []
                }
            
            categories[category]["count"] += 1
            categories[category]["total_views"] += page.get('screenPageViews', 0)
            
            if len(categories[category]["examples"]) < 3:
                categories[category]["examples"].append({
                    "path": path,
                    "title": page.get('pageTitle', ''),
                    "views": page.get('screenPageViews', 0)
                })
        
        return categories
    
    def _get_page_category(self, path):
        """í˜ì´ì§€ ê²½ë¡œë¡œ ì¹´í…Œê³ ë¦¬ íŒë‹¨"""
        if path == '/':
            return 'homepage'
        elif 'login' in path:
            return 'authentication'
        elif 'order' in path:
            return 'order_management'
        elif 'product' in path:
            return 'product_management'
        elif 'distribution' in path:
            return 'distribution'
        elif any(keyword in path for keyword in ['qna', 'support', 'help', 'guide']):
            return 'support'
        elif any(keyword in path for keyword in ['post', 'blog', 'news']):
            return 'content'
        else:
            return 'other'
    
    def _analyze_website_structure(self, pages_data):
        """ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡° ë¶„ì„"""
        structure = {
            "sections": {},
            "depth_analysis": {},
            "url_patterns": []
        }
        
        # ì„¹ì…˜ë³„ ë¶„ì„
        for page in pages_data:
            path = page.get('pagePath', '')
            parts = [p for p in path.split('/') if p]
            
            if parts:
                section = parts[0]
                if section not in structure["sections"]:
                    structure["sections"][section] = {
                        "pages": 0,
                        "total_views": 0,
                        "subsections": set()
                    }
                
                structure["sections"][section]["pages"] += 1
                structure["sections"][section]["total_views"] += page.get('screenPageViews', 0)
                
                if len(parts) > 1:
                    structure["sections"][section]["subsections"].add(parts[1])
        
        # setì„ listë¡œ ë³€í™˜ (JSON ì§ë ¬í™” ë•Œë¬¸)
        for section in structure["sections"]:
            structure["sections"][section]["subsections"] = list(structure["sections"][section]["subsections"])
        
        return structure
    
    def _analyze_traffic_sources(self, traffic_data):
        """íŠ¸ë˜í”½ ì†ŒìŠ¤ ë¶„ì„"""
        sources = {}
        
        for record in traffic_data:
            source = record.get('sessionSource', 'unknown')
            medium = record.get('sessionMedium', 'unknown')
            key = f"{source}/{medium}"
            
            if key not in sources:
                sources[key] = {
                    "sessions": 0,
                    "users": 0,
                    "pages": []
                }
            
            sources[key]["sessions"] += record.get('sessions', 0)
            sources[key]["users"] += record.get('activeUsers', 0)
            
            page_path = record.get('pagePath', '')
            if page_path and page_path not in sources[key]["pages"]:
                sources[key]["pages"].append(page_path)
        
        # ìƒìœ„ íŠ¸ë˜í”½ ì†ŒìŠ¤ë§Œ ì €ì¥
        top_sources = dict(sorted(sources.items(), key=lambda x: x[1]['sessions'], reverse=True)[:20])
        
        return {
            "top_sources": top_sources,
            "summary": {
                "total_sources": len(sources),
                "top_source": max(sources.items(), key=lambda x: x[1]['sessions'])[0] if sources else None
            }
        }
    
    def _analyze_events(self, events_data):
        """ì´ë²¤íŠ¸ ë¶„ì„"""
        events = {}
        conversion_events = []
        
        for record in events_data:
            event_name = record.get('eventName', '')
            
            if event_name not in events:
                events[event_name] = {
                    "total_count": 0,
                    "total_users": 0,
                    "pages": []
                }
            
            events[event_name]["total_count"] += record.get('eventCount', 0)
            events[event_name]["total_users"] += record.get('activeUsers', 0)
            
            page_path = record.get('pagePath', '')
            if page_path:
                events[event_name]["pages"].append(page_path)
            
            # ì „í™˜ ì´ë²¤íŠ¸ ì‹ë³„
            if any(keyword in event_name.lower() for keyword in ['íšŒì›ê°€ì…', 'êµ¬ë§¤', 'ì‹ ì²­', 'signup', 'purchase']):
                conversion_events.append({
                    "event_name": event_name,
                    "count": record.get('eventCount', 0),
                    "page": page_path
                })
        
        return {
            "all_events": events,
            "conversion_events": conversion_events,
            "top_events": dict(sorted(events.items(), key=lambda x: x[1]['total_count'], reverse=True)[:10])
        }
    
    def _analyze_user_journey(self, landing_data):
        """ì‚¬ìš©ì ì—¬ì • ë¶„ì„"""
        return {
            "top_entry_points": landing_data[:10],
            "high_bounce_pages": [
                page for page in landing_data 
                if page.get('bounceRate', 0) > 70
            ][:10],
            "best_engagement_pages": sorted(
                landing_data, 
                key=lambda x: x.get('engagementRate', 0), 
                reverse=True
            )[:10]
        }
    
    def _generate_business_insights(self, pages_data, traffic_data, events_data, landing_data):
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        return {
            "business_type": self._identify_business_type(pages_data),
            "key_functions": self._identify_key_functions(pages_data, events_data),
            "user_behavior_patterns": self._analyze_user_behavior(traffic_data, landing_data),
            "conversion_opportunities": self._identify_conversion_opportunities(events_data),
            "optimization_suggestions": self._generate_optimization_suggestions(pages_data, landing_data)
        }
    
    def _identify_business_type(self, pages_data):
        """ë¹„ì¦ˆë‹ˆìŠ¤ íƒ€ì… ì‹ë³„"""
        page_paths = [p.get('pagePath', '') for p in pages_data]
        
        if any('order' in path for path in page_paths):
            if any('distribution' in path for path in page_paths):
                return "B2B_distribution_platform"
            else:
                return "ecommerce_platform"
        elif any('product' in path for path in page_paths):
            return "product_management_platform"
        else:
            return "general_business_platform"
    
    def _identify_key_functions(self, pages_data, events_data):
        """í•µì‹¬ ê¸°ëŠ¥ ì‹ë³„"""
        page_categories = self._categorize_pages(pages_data)
        event_names = [e.get('eventName', '') for e in events_data]
        
        return {
            "primary_functions": list(page_categories.keys()),
            "key_events": list(set(event_names))[:10],
            "most_used_section": max(page_categories.items(), key=lambda x: x[1]['total_views'])[0] if page_categories else None
        }
    
    def _analyze_user_behavior(self, traffic_data, landing_data):
        """ì‚¬ìš©ì í–‰ë™ íŒ¨í„´ ë¶„ì„"""
        return {
            "primary_traffic_source": "direct" if any("direct" in t.get('sessionSource', '') for t in traffic_data) else "search",
            "avg_bounce_rate": sum(l.get('bounceRate', 0) for l in landing_data) / len(landing_data) if landing_data else 0,
            "engagement_pattern": "high" if sum(l.get('engagementRate', 0) for l in landing_data) / len(landing_data) > 30 else "moderate"
        }
    
    def _identify_conversion_opportunities(self, events_data):
        """ì „í™˜ ê¸°íšŒ ì‹ë³„"""
        conversion_events = [e for e in events_data if any(keyword in e.get('eventName', '').lower() for keyword in ['íšŒì›ê°€ì…', 'êµ¬ë§¤', 'ì‹ ì²­'])]
        
        return {
            "has_signup_tracking": any('íšŒì›ê°€ì…' in e.get('eventName', '') for e in events_data),
            "conversion_events_count": len(conversion_events),
            "conversion_pages": list(set(e.get('pagePath', '') for e in conversion_events))
        }
    
    def _generate_optimization_suggestions(self, pages_data, landing_data):
        """ìµœì í™” ì œì•ˆ ìƒì„±"""
        high_traffic_pages = [p for p in pages_data if p.get('screenPageViews', 0) > 1000]
        high_bounce_pages = [l for l in landing_data if l.get('bounceRate', 0) > 70]
        
        return {
            "high_traffic_pages_count": len(high_traffic_pages),
            "high_bounce_pages_count": len(high_bounce_pages),
            "optimization_priority": "bounce_rate" if len(high_bounce_pages) > 5 else "traffic_conversion"
        }
    
    def _print_summary(self, knowledge):
        """ìƒì„±ëœ ì§€ì‹ ìš”ì•½ ì¶œë ¥"""
        print("\nğŸ“Š ìƒì„±ëœ ì§€ì‹ ìš”ì•½")
        print("="*50)
        print(f"ğŸ“„ ì´ í˜ì´ì§€: {knowledge['pages']['total_pages']:,}ê°œ")
        print(f"ğŸ—ï¸ ì›¹ì‚¬ì´íŠ¸ ì„¹ì…˜: {len(knowledge['website_structure']['sections'])}ê°œ")
        print(f"ğŸš€ íŠ¸ë˜í”½ ì†ŒìŠ¤: {knowledge['traffic_sources']['summary']['total_sources']}ê°œ")
        print(f"ğŸ¯ ì´ë²¤íŠ¸ ì¢…ë¥˜: {len(knowledge['events']['all_events'])}ê°œ")
        print(f"ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ íƒ€ì…: {knowledge['business_insights']['business_type']}")
        print(f"ğŸ” ì „í™˜ ì¶”ì : {'ìˆìŒ' if knowledge['business_insights']['conversion_opportunities']['has_signup_tracking'] else 'ì—†ìŒ'}")

# ì‹¤í–‰
if __name__ == "__main__":
    # ì„¤ì •
    CREDENTIALS_PATH = "/Users/brich/Downloads/gareport/b-flow-407402-f835e3a78bf7.json"
    PROPERTY_ID = "302932513"
    
    # ì§€ì‹ ìƒì„±ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
    generator = WebsiteKnowledgeGenerator(CREDENTIALS_PATH, PROPERTY_ID)
    knowledge = generator.generate_knowledge_json("website_knowledge.json")
    
    print("\nğŸ‰ ì™„ë£Œ! 'website_knowledge.json' íŒŒì¼ì„ Claudeì—ê²Œ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    print("ê·¸ëŸ¬ë©´ ìì—°ì–´ ìš”ì²­ì— ë§ëŠ” GA4 ë¶„ì„ ì½”ë“œë¥¼ ìƒì„±í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤!")